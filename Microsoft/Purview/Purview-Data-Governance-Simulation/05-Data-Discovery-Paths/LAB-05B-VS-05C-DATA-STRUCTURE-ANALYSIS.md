# Lab 05b vs Lab 05c: Data Structure Analysis

## ğŸ“‹ Overview

This document analyzes the fundamental differences between Lab 05b (eDiscovery UI) and Lab 05c (Graph API Review Set) export formats, explaining how different workflow approaches result in different CSV structures.

**Analysis Date**: November 23, 2025

---

## ğŸ” Workflow Comparison

### Lab 05b: eDiscovery UI Direct Export Workflow

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Create eDiscovery Case (Manual UI)                      â”‚
â”‚  2. Create Content Search (Query Builder)                   â”‚
â”‚  3. Run Query â†’ Generate Results                            â”‚
â”‚  4. Click "Export" â†’ Direct Search Export                   â”‚
â”‚  5. Download Export Package (.zip)                          â”‚
â”‚  6. Extract â†’ Process with Analysis Script                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Characteristics**:
- **Direct export from search results** (no review set intermediary)
- **One row per file per SIT type** (file can appear multiple times)
- **Includes SiteName column** (parsed from export metadata)
- **FileURL format**: Local export path structure
- **Post-processing**: Analysis script aggregates per-file data
- **Export speed**: Fast (5-10 minutes for ~4,400 files)
- **Export metadata**: Results.csv with basic metadata

---

### Lab 05c: Graph API Review Set Workflow

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Create eDiscovery Case (Graph API)                      â”‚
â”‚  2. Create Content Search (API Query)                       â”‚
â”‚  3. Run Query â†’ Generate Results                            â”‚
â”‚  4. Create Review Set (API)                                 â”‚
â”‚  5. Add Search Results to Review Set (20-30 min backend)    â”‚
â”‚     â””â†’ Copy files from SharePoint/Exchange to Azure Storage â”‚
â”‚     â””â†’ Index content with SIT metadata                      â”‚
â”‚     â””â†’ Apply advanced processing (OCR, threading, etc.)     â”‚
â”‚  6. Export Review Set Data (API) (5-15 min)                 â”‚
â”‚  7. Download Export Package from Portal                     â”‚
â”‚  8. Extract â†’ Process with Analysis Script                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Characteristics**:

- **Export from review set** (not direct search results)
- **One row per file per SIT type** (file can appear multiple times)
- **No SiteName column** (only full SharePoint URL in Location)
- **Location format**: Full SharePoint URL with domain
- **Post-processing**: Analysis script must parse site from URL
- **Review set benefits**: Advanced filtering, tagging, analytics, OCR
- **Export metadata**: Enriched metadata from review set processing
- **Total time**: 25-45 minutes (collection + export)

---

## ğŸ”„ Review Set Collection Process (Lab 05c Only)

### What is a Review Set?

A **review set** is a secure, Microsoft-provided Azure Storage location that serves as an immutable, isolated workspace for detailed content analysis. When you add search results to a review set, Microsoft 365 performs extensive backend processing to prepare content for legal review, compliance analysis, and advanced discovery workflows.

### Review Set Collection Backend Operations

**The addToReviewSet operation performs these tasks:**

1. **Content Copying**:
   - Copies files from original M365 locations (SharePoint, Exchange, OneDrive) to dedicated Azure Storage
   - Creates immutable snapshots of content at time of collection
   - Preserves original metadata and file properties

2. **Advanced Indexing**:
   - Reindexes partially indexed items for full-text search
   - Extracts text from images using OCR (Optical Character Recognition)
   - Processes encrypted content and protected documents

3. **SIT Metadata Processing**:
   - Attaches detailed SIT detection metadata to each file
   - Pre-aggregates SIT instance counts per file
   - Applies confidence scoring and detection context

4. **Conversation Threading**:
   - Reconstructs email and Teams conversation threads
   - Groups related messages by ConversationId
   - Preserves reply chains and message context

5. **Family Grouping**:
   - Links attachments to parent emails
   - Groups embedded items with container documents
   - Creates FamilyId relationships for related content

6. **Analytics Preparation**:
   - Generates document hashes for duplicate detection
   - Calculates similarity scores for near-duplicate identification
   - Prepares data structures for advanced analytics queries

### Review Set vs. Direct Search Export

| Aspect | Lab 05b (Direct Export) | Lab 05c (Review Set Export) |
|--------|-------------------------|------------------------------|
| **Processing Time** | 5-10 minutes | 25-45 minutes (collection + export) |
| **Content Location** | Original M365 locations | Copied to Azure Storage |
| **Metadata Richness** | Basic search metadata | Enriched with analytics metadata |
| **Content Mutability** | Can change in source | Immutable snapshot |
| **Advanced Features** | Limited to search results | Full review set capabilities |
| **OCR Processing** | Not applied | Applied to images and scanned docs |
| **Conversation Threading** | Basic | Full thread reconstruction |
| **Duplicate Detection** | Not available | Hash-based duplicate identification |
| **Tagging Support** | Not available | Review set tagging and categorization |
| **Query Capabilities** | Search query only | Advanced review set filters and queries |

### Why Lab 05c Takes Longer

**Review Set Collection Time (20-30 minutes)**:

- **Content Volume**: ~4,400 files need individual copying and processing
- **Backend Operations**: OCR, threading, family grouping, and analytics preparation
- **Azure Storage Transfer**: Files copied from SharePoint/Exchange to review set storage
- **Indexing Overhead**: Full-text indexing and metadata enrichment
- **Quality Checks**: Content validation and integrity verification

**Review Set Export Time (5-15 minutes)**:

- **Package Generation**: Creating export packages from review set storage
- **Metadata Compilation**: Consolidating enriched metadata into export files
- **ZIP Compression**: Packaging files and metadata for download

**Total Time**: 25-45 minutes vs. 5-10 minutes for direct export

### When to Use Review Sets (Lab 05c Approach)

**Use review sets when you need:**

- **Advanced Analytics**: Duplicate detection, near-duplicate identification, threading
- **Content Tagging**: Apply labels and categories for review workflows
- **Immutable Collections**: Legal hold requirements for static content sets
- **OCR Processing**: Text extraction from images and scanned documents
- **Complex Filtering**: Advanced queries beyond simple search conditions
- **Conversation Context**: Full email and Teams conversation thread reconstruction
- **Predictive Coding**: Machine learning-based relevance prediction
- **Family Grouping**: Attachment and embedded item relationships
- **Collaboration**: Multiple reviewers working on the same content set
- **Audit Trail**: Track review actions, decisions, and annotations

**Use direct export (Lab 05b approach) when you need:**

- **Speed**: Fast results without review set overhead
- **Simple Discovery**: Basic SIT detection without advanced analytics
- **One-Time Analysis**: No need for ongoing review or collaboration
- **Current Content**: No requirement for immutable snapshots
- **Resource Efficiency**: Minimize Azure storage usage and processing costs

---

## ğŸ“Š CSV Structure Comparison

### Lab 05b CSV Structure (Direct Search Export)

**File**: `eDiscovery-Detailed-Analysis-2025-11-21-121118.csv`

**Column Schema**:
```
FileName        : BackgroundCheck_00020_2025-06-24.pdf
SiteName        : Legal-Simulation
LibraryName     : Shared Documents
FileURL         : Items.1.001.Lab05b_SIT_Discovery_Export.zip/SharePoint/Legal-Simulation/Shared Documents/BackgroundCheck_00020_2025-06-24.pdf
SIT_Type        : U.S. Individual Taxpayer Identification Number (ITIN)
DetectionCount  : 1
SampleMatches   : [eDiscovery export - content not included]
ConfidenceLevel : High
FileSize        : 520
Created         : 2025-11-17T06:14:32Z
ScanTimestamp   : 2025-11-21 12:11:18
DetectionMethod : eDiscovery Compliance Search
```

**Key Features**:
- âœ… **SiteName column present** - Direct site identification
- âœ… **LibraryName column** - Document library context
- âœ… **FileURL** - Local export package path structure
- âœ… **SampleMatches** - Content preview (if included in export)
- âœ… **Created timestamp** - File creation date
- âœ… **ScanTimestamp** - When analysis was performed
- âœ… **DetectionMethod** - Identifies Lab 05b workflow

**Data Granularity**: One row per file per SIT type per detection

**Example**: A file with 2 SSN instances and 1 ITIN instance = **3 CSV rows**

---

### Lab 05c CSV Structure (Review Set Export)

**File**: `SIT_Discovery_Summary_2025-11-22_110656.csv`

**Column Schema**:
```
FileName     : BenefitsEnrollment_EMP-10001_2025-06-04.xlsx
Location     : https://marcusjcloud.sharepoint.com/sites/HR-Simulation/_layouts/15/Doc.aspx?sourcedoc=%7B22F9E2D9-FC32-44AC-ACFA-98E5EFF2A2F0%7D&file=BenefitsEnrollment_EMP-10001_2025-06-04.xlsx&action=default&mobileredirect=true
SITType      : U.S. Social Security Number (SSN)
SITInstances : 3
Confidence   : 95
LastModified : 11/17/2025 5:36:41 AM
Size         : 0.7
Owner        : Marcus Jacobson
```

**Key Features**:
- âŒ **No SiteName column** - Must be parsed from Location URL
- âœ… **Location** - Full SharePoint URL (https://...)
- âœ… **SITType** - Friendly SIT name (no GUID)
- âœ… **SITInstances** - Count of detections for this SIT in this file
- âœ… **Confidence** - Numeric confidence score (85-100)
- âœ… **LastModified** - File modification timestamp
- âœ… **Size** - File size in KB
- âœ… **Owner** - File owner/author

**Data Granularity**: One row per file per SIT type (aggregated instances)

**Example**: A file with 3 SSN instances and 1 ITIN instance = **2 CSV rows** (aggregated)

---

## ğŸ”‘ Critical Differences

### 1. Site Identification Method

| Aspect | Lab 05b | Lab 05c |
|--------|---------|---------|
| **Column Name** | `SiteName` | `Location` (full URL) |
| **Format** | "HR-Simulation" | `https://tenant.sharepoint.com/sites/HR-Simulation/...` |
| **Parsing Required** | âŒ No - Direct column | âœ… Yes - Extract from URL |
| **Reliability** | âœ… High - Explicit | âœ… High - URL structure |

**Lab 05c Site Extraction Pattern**:
```powershell
# From: https://marcusjcloud.sharepoint.com/sites/HR-Simulation/_layouts/15/...
# Extract: "HR-Simulation"

if ($row.Location -match '/sites/([^/]+)') {
    $siteName = $matches[1]
}
```

---

### 2. File Location Representation

| Aspect | Lab 05b | Lab 05c |
|--------|---------|---------|
| **URL Type** | Local export path | Full SharePoint URL |
| **Example** | `Items.1.001.Lab05b_Export.zip/SharePoint/...` | `https://tenant.sharepoint.com/sites/...` |
| **Clickable** | âŒ No - Local path | âœ… Yes - Direct link |
| **Portal Integration** | âŒ No | âœ… Yes - Opens in browser |

---

### 3. SIT Detection Aggregation

| Aspect | Lab 05b | Lab 05c |
|--------|---------|---------|
| **Row Per Detection** | âœ… Yes - One row per SIT instance | âŒ No - Aggregated by SIT type |
| **Instance Count** | Implicit (count rows) | Explicit (`SITInstances` column) |
| **File Uniqueness** | Multiple rows per file | Multiple rows per file (fewer) |
| **Analysis Complexity** | Group-Object to aggregate | Direct - already aggregated |

**Example Comparison**:

**File**: `BenefitsEnrollment_EMP-10001.xlsx` contains:
- 3 SSN detections
- 1 ITIN detection

**Lab 05b Output** (4 rows):
```
Row 1: FileName=EMP-10001.xlsx, SIT_Type=SSN, DetectionCount=1
Row 2: FileName=EMP-10001.xlsx, SIT_Type=SSN, DetectionCount=1
Row 3: FileName=EMP-10001.xlsx, SIT_Type=SSN, DetectionCount=1
Row 4: FileName=EMP-10001.xlsx, SIT_Type=ITIN, DetectionCount=1
```

**Lab 05c Output** (2 rows):
```
Row 1: FileName=EMP-10001.xlsx, SITType=SSN, SITInstances=3
Row 2: FileName=EMP-10001.xlsx, SITType=ITIN, SITInstances=1
```

---

### 4. Metadata Differences

| Column | Lab 05b | Lab 05c | Notes |
|--------|---------|---------|-------|
| SiteName | âœ… Present | âŒ Absent | Must parse from Location URL |
| LibraryName | âœ… Present | âŒ Absent | Review set doesn't include |
| Owner | âŒ Absent | âœ… Present | Review set includes metadata |
| Size | âœ… Present (bytes) | âœ… Present (KB) | Different units |
| Confidence | âœ… High/Medium/Low | âœ… Numeric (85-100) | Different formats |
| Created | âœ… ISO timestamp | âŒ Absent | Lab 05b includes creation date |
| LastModified | âŒ Absent | âœ… Date/time | Lab 05c includes modification date |
| SampleMatches | âœ… Optional | âŒ Absent | Lab 05b can include content preview |

---

## ğŸ¯ Impact on Cross-Lab Analysis Script

### Current Issue

The cross-lab analysis script's Lab 05c normalization code (lines 388-394) is missing site extraction:

```powershell
'Lab05c' {
    # Current code - NO SITE FIELD
    $csvData | Select-Object @{Name='FileName'; Expression={$_.FileName}},
                             @{Name='SITType'; Expression={Resolve-SITName -SITType $_.SITType -GuidMapping $sitGuidMapping}},
                             @{Name='Location'; Expression={$_.Location}},
                             @{Name='DetectionMethod'; Expression={'Graph-API-Purview'}}
}
```

**Result**: Site distribution analysis shows "No site data available" for Lab 05c.

---

### Required Fix

Add site name extraction from Location URL:

```powershell
'Lab05c' {
    # Fixed code - EXTRACT SITE FROM URL
    $csvData | Select-Object @{Name='FileName'; Expression={$_.FileName}},
                             @{Name='SITType'; Expression={Resolve-SITName -SITType $_.SITType -GuidMapping $sitGuidMapping}},
                             @{Name='Site'; Expression={
                                 if ($_.Location -match '/sites/([^/]+)') {
                                     $matches[1]
                                 } else {
                                     'Unknown-Site'
                                 }
                             }},
                             @{Name='Location'; Expression={$_.Location}},
                             @{Name='DetectionMethod'; Expression={'Graph-API-Purview'}}
}
```

---

## ğŸ“Š Detection Count Reconciliation

### Why Lab 05c Shows Fewer Files (3,189 vs 4,423)

**Root Cause**: Lab 05c CSV is **pre-aggregated** by Graph API export.

**Lab 05b Detailed Structure**:
```
4,423 unique files Ã— average 2.3 SIT types per file = ~10,308 CSV rows
```

**Lab 05c Aggregated Structure**:
```
3,189 CSV rows already represent unique file+SIT combinations
```

**Hypothesis**: The 3,189 vs 4,423 discrepancy suggests:
1. Lab 05c export may have filtered some files during review set collection
2. Timing difference: Lab 05c ran 24+ hours after Lab 05b
3. Review set export may exclude certain file types or sizes
4. Export settings may differ between direct search export vs review set export

**Validation Needed**:
```powershell
# Count unique files in Lab 05c
$lab05cFiles = Import-Csv "SIT_Discovery_Summary_*.csv"
$uniqueFiles = $lab05cFiles.FileName | Select-Object -Unique
Write-Host "Unique files in Lab 05c: $($uniqueFiles.Count)"

# Compare with Lab 05b
$lab05bFiles = Import-Csv "eDiscovery-Detailed-Analysis-*.csv"
$uniqueFilesLab05b = $lab05bFiles.FileName | Select-Object -Unique
Write-Host "Unique files in Lab 05b: $($uniqueFilesLab05b.Count)"

# Find files in Lab 05b but not in Lab 05c
$missingInLab05c = $uniqueFilesLab05b | Where-Object { $uniqueFiles -notcontains $_ }
Write-Host "Files in Lab 05b but not Lab 05c: $($missingInLab05c.Count)"
```

---

## ğŸ”§ Recommended Script Updates

### 1. Fix Lab 05c Site Extraction (Priority: HIGH)

**File**: `Invoke-CrossLabAnalysis.ps1`  
**Lines**: 388-394  
**Action**: Add Site extraction from Location URL

### 2. Add Data Structure Validation (Priority: MEDIUM)

Add diagnostic output to show:
- CSV column headers for each lab
- Row count vs unique file count
- Aggregation level detection

### 3. Update Documentation (Priority: LOW)

**Files to Update**:
- `CROSS-LAB-ANALYSIS.md` - Add section on data structure differences
- Lab 05b README - Clarify direct search export workflow
- Lab 05c README - Clarify review set export workflow

---

## ğŸ“š Key Takeaways

### Workflow Differentiation Benefits

**Lab 05b (Direct Search Export)**:
- âœ… Faster workflow (no review set creation/collection)
- âœ… Explicit site and library metadata
- âœ… Lower data volume (direct export)
- âœ… Content preview capability (SampleMatches)
- âŒ Less metadata (no Owner, no LastModified)

**Lab 05c (Review Set Export)**:
- âœ… API automation-friendly (programmatic)
- âœ… Rich metadata (Owner, LastModified, Size)
- âœ… Pre-aggregated detection counts
- âœ… Direct SharePoint URLs (clickable)
- âŒ Site name must be parsed from URL
- âŒ Additional review set collection time (20-30 min)

---

### Cross-Lab Analysis Implications

1. **Data Normalization Required**: Different CSV structures require custom parsing per lab
2. **Site Extraction**: Lab 05c needs URL parsing to match Lab 05a/05b site names
3. **Aggregation Awareness**: Lab 05c rows already aggregated; Lab 05b requires Group-Object
4. **File Count Discrepancies**: Expected due to different export workflows and timing
5. **Metadata Differences**: Each lab provides different contextual information

---

## âœ… Next Steps

1. **Implement Lab 05c site extraction fix** in cross-lab analysis script
2. **Validate file count reconciliation** to understand 3,189 vs 4,423 difference
3. **Document workflow advantages** of each approach in lab READMEs
4. **Test cross-lab comparison** after site extraction fix
5. **Update configuration guide** to explain data structure differences

---

## ğŸ¤– AI-Assisted Content Generation

This data structure analysis was created with the assistance of **GitHub Copilot** powered by advanced AI language models. The analysis was generated through systematic examination of actual Lab 05b and Lab 05c export files, comparing CSV structures, workflow differences, and metadata characteristics to provide comprehensive documentation for cross-lab analysis development.

*AI tools were used to enhance productivity and ensure thorough analysis of eDiscovery export formats while maintaining technical accuracy and reflecting the real-world differences between manual UI workflows and API-driven automation approaches.*
