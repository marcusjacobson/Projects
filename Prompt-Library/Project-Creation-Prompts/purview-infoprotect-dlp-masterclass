# New Project Creation Prompt Template

This prompt template provides a structured approach for creating new projects from scratch using GitHub Copilot or other AI assistants. It ensures compliance with repository style guides, follows best practices, and iterates on project structure before implementation.

---

## ðŸŽ¯ Universal AI Project Creation Prompt

```markdown
I need your help creating a new project from scratch. Please follow this structured approach:

## PROJECT CONTEXT

**Skill Area / Domain Expertise Required:**
Microsoft Purview Information Protection, Data Loss Prevention (DLP), M365 Compliance, Azure DevOps, PowerShell, Infrastructure as Code (IaC), Microsoft Graph API.

**Specific Targeted Content:**
Create a comprehensive "Purview-Retail-Data-Protection-Masterclass" project that simulates a real-world governance environment for a large retail chain.
- **Scenario**: A large retail organization needs to protect customer PII and PCI-DSS data across their M365 estate.
- **Data Foundation**: Create scripts to generate and load realistic dummy data (customer PII, credit card numbers, internal memos, retail store reports) into:
  - SharePoint Online (Department sites: HR, Finance, Retail Ops)
  - OneDrive for Business (User documents)
  - Exchange Online (Email traffic simulation)
  - Microsoft Teams (Channel messages and files)
  - Copilot (Ensure data is semantically rich to demonstrate Copilot interactions and test DLP/Label inheritance to prevent exfiltration via Copilot)
- **Classification Taxonomy**: Implement a standard 4-Tier model (Public, Internal, Confidential, Highly Confidential) PLUS specific PCI-DSS regulatory labels.
- **Phase 1 (UI-Based)**: Detailed step-by-step guides to manually build and manage governance policies (Sensitivity Labels, DLP Policies, Auto-labeling) using the Purview Portal.
  - **Advanced Classification**: Include labs for **Document Fingerprinting** (e.g., "Store Incident Report" template) and **Exact Data Match (EDM)** (simulating a customer database) to demonstrate high-fidelity matching.
    - **EDM Source**: Generate a **CSV/JSON schema file** to serve as the "Customer Database" source of truth for EDM hashing and uploading.
- **Supplemental IaC Labs**: A dedicated section for automating the deployment of similar policies using PowerShell and Azure Pipelines.
  - **Conflict Avoidance**: Use distinct naming conventions (e.g., prefix `IaC-`) for automated resources so they can coexist with Phase 1 UI-created resources in the same tenant.
  - **Automation Focus**: Use **Service Principal authentication** (Certificate-based) for all automation. Use Delegated User authentication only where Service Principals are strictly not supported.
- **Documentation**: Microsoft Learn as the central source of truth. Include placeholders for screenshots in all UI-based guides.

**Target File Types to Create:**
- PowerShell scripts (.ps1) for data generation, loading, and policy automation.
- YAML pipelines (.yml) for Azure DevOps integration.
- Markdown docs (.md) for lab guides and documentation.
- JSON configs (.json) for policy definitions and data templates.

**Organization & Structure Requirements:**
- `00-Prerequisites/`: Service Principal setup, Certificate generation, App Registration, and **Purview Pay-As-You-Go (PAYG) Resource Creation** (reference existing Purview labs for setup steps).
  - **Permission Documentation**: The `README.md` in this folder MUST explicitly list the **Required Graph API Permissions** (e.g., `InformationProtectionPolicy.Read.All`) needed for all subsequent automation labs to prevent 403 errors.
- `01-Data-Foundation/`: Scripts to generate and load dummy data into M365 services.
- `02-Classification-Design/`: Documentation of the 4-Tier + PCI-DSS taxonomy.
- `03-UI-Configuration/`: Step-by-step guides for manual policy creation (with screenshot placeholders).
- `04-Supplemental-IaC-Labs/`:
  - **Structure this directory to mirror the `Entra-Deployment-Pipelines` repository pattern**:
    - `Subject-Area/` (e.g., `Information-Protection/`, `Data-Loss-Prevention/`, `Data-Classification/`)
      - `Specific-Deployment/` (e.g., `Deploy-Sensitivity-Labels/`, `Deploy-Custom-SITs/`, `Deploy-AutoLabeling-Policies/`)
        - `Pipeline/`: Contains the YAML pipeline definition.
        - `Scripts/`: Contains the PowerShell logic.
        - `Template/`: Contains any JSON/config templates.
  - **Required IaC Scenarios**:
    1. **Custom SITs**: Automate the creation of a custom Sensitive Information Type (e.g., "Retail Project Code") using Regex patterns.
    2. **Sensitivity Labels**: Automate the creation and publication of the label taxonomy.
    3. **Auto-Labeling**: Automate a service-side auto-labeling policy for SharePoint/OneDrive.
    4. **DLP Policies**: Automate a financial DLP policy.
- `scripts/`: Shared utility scripts (e.g., `Connect-PurviewGraph.ps1`).

**Reference Project Strategy:**
- Review the existing projects in the repository for reusable patterns, style compliance, and structure:
  - **Pipeline Structure**: Reference `Microsoft/Entra/Entra-Deployment-Pipelines` for the pattern of YAML pipelines + YAML variables + external scripts.
  - **Authentication**: Reference `Microsoft/Multi-Discipline-Projects/Fabric-Purview-Governance-Simulation` for known good Service Principal authentication patterns.
  - **Discovery**: Reference `Microsoft/Purview/Purview-Discovery-Methods-Simulation` for data discovery concepts.- **Reuse Known-Good Processes**:
  - **Authentication**: Do NOT reinvent authentication. Reuse the exact Service Principal connection scripts and patterns found in `Fabric-Purview-Governance-Simulation` or `Entra-Deployment-Pipelines`.
  - **Data Generation**: Reuse existing data generation logic where possible, but adapt it to the Retail scenario.- **CRITICAL**: Duplicate and customize content rather than linking to it - this project must be fully self-contained.
- Extract applicable PowerShell script patterns, documentation structures, and step-by-step procedures.
- Do NOT assume any work from reference projects has been completed.
- Do NOT create references or links to other projects - embed all necessary content directly.

**Additional Context:**
This is a "from scratch" setup. The goal is to move from a manual "click-ops" understanding (Phase 1) to a mature DevSecOps approach (Phase 2). The "Retail" scenario should drive the choice of Sensitive Information Types (SITs) and data examples.

**CISO/Compliance Officer Requirements (Security & Realism):**
- **License Scope (E5 + PAYG)**: Assume the environment has **Microsoft 365 E5** (or E5 Compliance) licenses AND a **Purview Pay-As-You-Go (PAYG)** resource enabled.
  - **Maximize PAYG Features**: Explicitly include labs that leverage PAYG capabilities within the **Information Protection** and **DLP** nodes.
  - **Enable Premium M365 Features**: Include labs for **Auto-labeling** (service-side and client-side), **Endpoint DLP**, **Teams Chat DLP**, **Document Fingerprinting**, and **Exact Data Match (EDM)**.
  - **Cost Awareness**: While maximizing PAYG features for IP/DLP, clearly document any potential consumption costs associated with these specific features.
- **High-Fidelity Data Generation**: Dummy data MUST pass standard checksums (e.g., Luhn algorithm for Credit Cards) and include contextual keywords (e.g., "CVV", "Expiry") to trigger **High Confidence** DLP matches. Random numbers are not sufficient.
  - **Volume Strategy**: Generate enough data to provide meaningful results and reporting (e.g., 50-100 files per department), but avoid excessive volumes that increase deployment time and complexity. Quality > Quantity.
- **Exfiltration Simulation (Full E5 Capabilities)**:
  - **Endpoint Exfiltration**: Simulate a user attempting to copy sensitive files to a USB drive or upload to personal cloud storage (Endpoint DLP).
  - **Teams Exfiltration**: Simulate a user pasting credit card numbers into a Teams chat (Teams DLP).
  - **Sharing Exfiltration**: Simulate a user creating an anonymous sharing link for a sensitive document (SPO/OD DLP).
- **False Positive Management**: Intentionally generate "noise" data (e.g., 16-digit project codes that look like CC numbers but aren't) and include a lab on **Tuning & Exception Management** to reduce alert fatigue.
  - **Simulation Mode**: Explicitly include a lab on running DLP policies in **Simulation Mode** first, analyzing the results, and then promoting to "Turned On" (Enforced).
  - **Phased Rollout**: Structure the DLP labs to follow a "Crawl-Walk-Run" methodology:
    1.  **Audit Only**: Log matches without blocking.
    2.  **Block with Override**: Allow users to provide a business justification.
    3.  **Block**: Strict enforcement for high-confidence matches.
- **Audit & Validation**: Dedicate a section to **Content Explorer** and **Activity Explorer** to prove compliance.
- **Least Privilege**: Ensure all automation scripts use the minimum required Graph API permissions.

**Timing & Sequencing Strategy (CRITICAL):**
- **Day 0 / Day 1 Priority**: Identify and prioritize "Long-Lead" items that require significant backend processing time.
  - **EDM Schema Indexing**: Can take 24+ hours.
  - **Sensitivity Label Publication**: Can take 24-48 hours to fully propagate to all apps.
  - **DLP Policy Sync**: Can take up to 24 hours for endpoint enforcement.
  - **Endpoint DLP Settings**: Enable "Evidence Collection" and "Onboarding" settings immediately.
- **Project Structure Implication**: Create a dedicated `01-Day-Zero-Setup` folder that contains these specific configurations.
  - The lab guide for this section must explicitly state: "Execute these configurations immediately upon starting the project to allow for backend processing time while you work on other labs."

**User & License Management:**
- The project should support two paths:
  1. **Existing Entra Simulation Users**: Users may have already deployed the `Entra-Zero-Trust-RBAC-Simulation`. If so, leverage these existing users/groups for personal data locations (OneDrive, Teams).
  2. **Standalone Deployment**: Include scripts/instructions to create necessary users/groups if the Entra simulation hasn't been run.
- **License Guidance**: Advise that an **M365 E5** (or E5 Compliance) subscription is required for full lab functionality (Auto-labeling, Endpoint DLP), but note which labs are compatible with E3.

## COMPLIANCE REQUIREMENTS

Before creating any content, you MUST:

1. **Review Repository Style-Guides:**
   - Read and understand the Markdown Style Guide (`Repository-Management/Style-Guides/markdown-style-guide.md`)
   - Read and understand the PowerShell Style Guide (`Repository-Management/Style-Guides/powershell-style-guide.md`) if applicable
   - Read and understand the Parameters File Style Guide (`Repository-Management/Style-Guides/parameters-file-style-guide.md`) if applicable
   - Follow any other relevant style guides in the repository

2. **Review Existing Reference Projects:**
   - Use `semantic_search` or `read_file` to extract relevant patterns, scripts, and documentation structures from the projects listed above.
   - Identify reusable PowerShell modules, error handling patterns, and documentation templates.

3. **Follow Copilot Instructions:**
   - Adhere to all standards defined in `.github/copilot-instructions.md`.
   - Apply appropriate style guide compliance for each file type.
   - Use proper formatting, headers, punctuation, and structure.
   - Include AI-assisted content generation acknowledgments where required.

4. **Apply Best Practices:**
   - Use proper naming conventions for files and resources.
   - Implement consistent formatting and organization.
   - Include comprehensive documentation and comments.
   - Follow industry standards for the specified technology stack.

5. **Research and Validate Before Creating:**
   - **NEVER rely on training data** for step-by-step instructions, code examples, or technical procedures.
   - **USE DEEP REASONING AGENTS**: Always use deep reasoning models (e.g., Claude with extended thinking, GPT-o1, Gemini Deep Research) when performing research, analysis, or architectural decisions.
   - **PRIMARY SOURCE**: Always use Microsoft Learn (`learn.microsoft.com`) as the primary validation source for Microsoft technologies.
   - **SECONDARY SOURCES**: Validate against official documentation (`docs.microsoft.com`, `github.com/Microsoft`, official vendor docs).
   - **Code Validation**: Research current API versions, cmdlet syntax, SDK methods, and library versions before suggesting code.
   - **UI/Portal Instructions**: Use `fetch_webpage` or documentation search to verify current portal navigation, menu locations, and button names.
   - **Version Checking**: Confirm current versions, features, and deprecated methods before providing examples.

## REQUIRED ITERATIVE APPROVAL PROCESS

### Phase 1: Project Structure Proposal

Before creating ANY files or content:

1. **Engage deep reasoning** for architectural analysis and technology selection.
2. **Review existing reference projects** to identify reusable patterns and content.
3. **Suggest a descriptive project name** that follows repository naming conventions.
4. **Propose a complete directory structure** showing all folders and key files.
5. **Explain the purpose** of each major directory and file type.
6. **Describe the organization rationale** and how it meets the requirements.
7. **Define the Skills Coverage Matrix** showing which specific skills/technologies are covered in each lab/section.
8. **Identify content to duplicate** from reference projects and how it will be adapted.
9. **Wait for my approval or feedback** before proceeding.

### Phase 2: Iterative Refinement

If I request changes:

1. **Revise the proposed structure** based on my feedback.
2. **Explain the changes made** and why they address my concerns.
3. **Present the updated proposal** for review.
4. **Repeat this process** until I explicitly approve the structure.

### Phase 3: Implementation

Only after I provide explicit approval:

1. **Create the directory structure** as approved.
2. **Generate all files** following the repository style guides.
3. **Ensure compliance** with all formatting and documentation standards.
4. **Provide a summary** of what was created and next steps.

## OUTPUT FORMAT REQUIREMENTS

### For Project Structure Proposal:

```text

## Proposed Project Structure

**Project Name:** [descriptive-project-name]

**Directory Tree:**

```text
project-root/
â”œâ”€â”€ README.md
â”œâ”€â”€ directory1/
â”‚   â”œâ”€â”€ subdirectory/
â”‚   â”‚   â”œâ”€â”€ file1.ext
â”‚   â”‚   â””â”€â”€ file2.ext
â”‚   â””â”€â”€ file3.ext
â”œâ”€â”€ directory2/
â”‚   â”œâ”€â”€ file4.ext
â”‚   â””â”€â”€ file5.ext
â””â”€â”€ directory3/
    â””â”€â”€ file6.ext
```

**Directory Purpose Explanations:**

- **[Directory Name]**: [Explanation of purpose and contents]
- **[Directory Name]**: [Explanation of purpose and contents]
...

**Skills Coverage Matrix:**

| Skill / Technology | Lab / Section | Depth (Basic/Intermediate/Advanced) |
|-------------------|---------------|-------------------------------------|
| [Skill 1]         | [Lab 01]      | [Depth]                             |
| [Skill 2]         | [Lab 02]      | [Depth]                             |
...

**Organization Rationale:**
[Explain why this structure was chosen and how it supports the learning objectives.]

**Key File Types to be Created:**

- [File Type]: [Count] - [Description]
...

**Compliance Considerations:**

- [List specific style guides and standards to be followed]

**Research Validation Plan:**

- [List specific documentation sources and APIs to be researched]

**Content Reuse from Reference Projects:**

- [List specific patterns or content to be adapted from existing repo projects]

**Awaiting Approval:** Please review this structure and provide feedback or approval to proceed.

```

### For Iterative Refinement:

```text

## Revised Project Structure (Version [N])

**Changes Made Based on Feedback:**

1. [Change 1]
2. [Change 2]
...

**Updated Directory Tree:**
...

**Updated Rationale:**
...

**Awaiting Approval:** Please review these revisions and provide feedback or approval to proceed.
```

## RESEARCH AND VALIDATION REQUIREMENTS

Before suggesting any code, step-by-step instructions, or technical procedures, you MUST validate against official sources:

### Primary Research Sources (in order of priority)

1. **Microsoft Learn** (learn.microsoft.com) - Primary source for all Microsoft technologies
2. **Official Microsoft Documentation** (docs.microsoft.com, github.com/Microsoft)
3. **Cloud Provider Official Docs** (Azure, AWS, GCP official documentation)
4. **Official Product Documentation** (Vendor-specific docs for third-party tools)
5. **Reputable Technical Resources** (Only after validating with official sources)

### What Requires Research Validation

**ALWAYS research before providing:**

- **Step-by-step instructions** for portal navigation, admin centers, or product UIs
- **Code examples** including API calls, cmdlet syntax, SDK methods
- **Configuration procedures** for Azure resources, services, or integrations
- **Installation workflows** and setup procedures
- **API endpoints** and authentication requirements
- **Resource properties** and configuration options
- **Current versions** of software, APIs, or services
- **Deprecated features** or replaced functionality

**Research Process:**

1. **Engage deep reasoning** for complex analysis, architectural decisions, or multi-faceted research
2. **Identify what needs validation** (UI paths, code syntax, API versions, etc.)
3. **Use appropriate research tools** (fetch_webpage for documentation, semantic search for internal patterns)
4. **Verify current state** (check dates, versions, and "as of" indicators)
5. **Cross-reference when uncertain** (use multiple official sources)
6. **Document research** (note version numbers, dates, and source URLs in comments)

## CRITICAL RULES

1. **Never skip the approval phase** - Always wait for explicit approval before creating files.
2. **Never assume project structure** - Always propose and iterate based on feedback.
3. **Always read style guides first** - Ensure compliance from the start, not as an afterthought.
4. **Always review reference projects** - Use semantic_search and read_file to extract reusable patterns.
5. **Always duplicate, never link** - Extract and embed content directly; never create references or links to other projects.
6. **Always validate against official documentation** - Never rely on training data for technical instructions, code examples, or current procedures.
7. **Always use deep reasoning agents** - Engage extended thinking/deep reasoning models for research, analysis, architectural decisions, and technology validation.
8. **Always research before suggesting** - Use Microsoft Learn for Microsoft technologies, official vendor docs for other technologies.
9. **Always provide detailed explanations** - Help me understand your design decisions.
10. **Always be ready to iterate** - Expect multiple rounds of refinement.
11. **Never create partial implementations** - Wait for full approval of the complete structure.

## STYLE GUIDE COMPLIANCE CHECKLIST

Before implementing, verify:

- [ ] Reviewed applicable style guides from `Repository-Management/Style-Guides/` directory.
- [ ] Reviewed existing reference projects for reusable patterns.
- [ ] Identified PowerShell scripts, documentation templates, and configuration files to duplicate.
- [ ] Planned content extraction strategy - no links or references, only embedded duplicated content.
- [ ] Understood repository `.github/copilot-instructions.md` requirements.
- [ ] Confirmed file naming conventions for target technology.
- [ ] Identified required documentation standards.
- [ ] Planned for AI-assisted content generation acknowledgments.
- [ ] Understood header, formatting, and punctuation requirements.
- [ ] Identified any technology-specific patterns to follow.
- [ ] **Researched current documentation** from Microsoft Learn or official sources for all technical content.
- [ ] **Validated API versions, cmdlet syntax, and library versions** against current official documentation.
- [ ] **Verified UI navigation paths and portal instructions** using current official resources (not training data).
- [ ] **Engaged deep reasoning agents** for architectural decisions, technology selection, and complex analysis.

```

---

## ðŸ¤– AI-Assisted Content Generation

This project creation prompt template was created with the assistance of **GitHub Copilot** powered by advanced AI language models. The content was generated, structured, and refined through iterative collaboration between human expertise and AI assistance within **Visual Studio Code**, incorporating best practices for AI prompting, multi-model compatibility, and repository-specific compliance requirements.

*AI tools were used to enhance productivity and ensure comprehensive coverage of project creation workflows while maintaining technical accuracy and reflecting established repository standards for content creation and style guide adherence.*
